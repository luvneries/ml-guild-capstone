{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations on GCP with TensorFlow and WALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project deploys a solution for a recommendation service on docker container/GCP APP engine, using the WALS algorithm in TensorFlow. Components include:\n",
    "\n",
    "- Recommendation model code, and scripts to train and tune the model on ML Engine\n",
    "- A REST endpoint using docker and nginx server.\n",
    "- Web App to show personalized and popular recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'mlongcp' # REPLACE WITH YOUR PROJECT ID\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR REGION e.g. us-central1\n",
    "\n",
    "# Set GCP variables\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = 'recserve_' + PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "# DO NOT expose/share project service account json.\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../../sv_mlongcp.json' # Path to service account file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not creating recserve_bucket since it already exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# create GCS bucket with recserve_PROJECT_NAME if not exists\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "if [ -n \"$exists\" ]; then\n",
    "   echo \"Not creating recserve_bucket since it already exists.\"\n",
    "else\n",
    "   echo \"Creating recserve_bucket\"\n",
    "   gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data files into our bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://recserve_mlongcp/data/ga_sessions_sample.json.gz...\n",
      "Copying gs://recserve_mlongcp/data/ga_sessions_sample_schema.json...\n",
      "Copying gs://recserve_mlongcp/data/recommendation_events.csv...\n",
      "Copying gs://recserve_mlongcp/data/u.data...\n",
      "/ [0/4 files][    0.0 B/133.2 MiB]   0% Done                                    \r",
      "/ [0/4 files][    0.0 B/133.2 MiB]   0% Done                                    \r",
      "/ [0/4 files][    0.0 B/133.2 MiB]   0% Done                                    \r",
      "/ [0/4 files][    0.0 B/133.2 MiB]   0% Done                                    \r",
      "/ [1/4 files][ 13.9 KiB/133.2 MiB]   0% Done                                    \r",
      "-\r",
      "- [1/4 files][  3.4 MiB/133.2 MiB]   2% Done                                    \r",
      "\\\r",
      "\\ [2/4 files][  4.7 MiB/133.2 MiB]   3% Done                                    \r",
      "|\r",
      "| [2/4 files][  8.6 MiB/133.2 MiB]   6% Done                                    \r",
      "/\r",
      "-\r",
      "- [2/4 files][ 12.7 MiB/133.2 MiB]   9% Done                                    \r",
      "\\\r",
      "|\r",
      "| [2/4 files][ 15.8 MiB/133.2 MiB]  11% Done                                    \r",
      "/\r",
      "/ [2/4 files][ 19.4 MiB/133.2 MiB]  14% Done                                    \r",
      "-\r",
      "\\\r",
      "\\ [2/4 files][ 23.6 MiB/133.2 MiB]  17% Done                                    \r",
      "|\r",
      "| [2/4 files][ 27.7 MiB/133.2 MiB]  20% Done                                    \r",
      "/\r",
      "-\r",
      "- [2/4 files][ 31.8 MiB/133.2 MiB]  23% Done                                    \r",
      "\\\r",
      "|\r",
      "| [2/4 files][ 35.9 MiB/133.2 MiB]  26% Done                                    \r",
      "/\r",
      "-\r",
      "- [2/4 files][ 38.8 MiB/133.2 MiB]  29% Done   3.6 MiB/s ETA 00:00:26           \r",
      "\\\r",
      "\\ [2/4 files][ 42.4 MiB/133.2 MiB]  31% Done   3.5 MiB/s ETA 00:00:26           \r",
      "|\r",
      "/\r",
      "/ [2/4 files][ 46.5 MiB/133.2 MiB]  34% Done   3.5 MiB/s ETA 00:00:25           \r",
      "-\r",
      "- [2/4 files][ 49.6 MiB/133.2 MiB]  37% Done   3.3 MiB/s ETA 00:00:25           \r",
      "\\\r",
      "|\r",
      "| [2/4 files][ 53.5 MiB/133.2 MiB]  40% Done   3.4 MiB/s ETA 00:00:23           \r",
      "/\r",
      "-\r",
      "- [2/4 files][ 56.8 MiB/133.2 MiB]  42% Done   3.5 MiB/s ETA 00:00:22           \r",
      "\\\r",
      "\\ [2/4 files][ 59.6 MiB/133.2 MiB]  44% Done   3.2 MiB/s ETA 00:00:23           \r",
      "\\ [3/4 files][ 59.6 MiB/133.2 MiB]  44% Done   3.2 MiB/s ETA 00:00:23           \r",
      "|\r",
      "/\r",
      "/ [3/4 files][ 62.4 MiB/133.2 MiB]  46% Done   3.0 MiB/s ETA 00:00:24           \r",
      "-\r",
      "\\\r",
      "\\ [3/4 files][ 66.5 MiB/133.2 MiB]  49% Done   3.1 MiB/s ETA 00:00:21           \r",
      "|\r",
      "| [3/4 files][ 70.4 MiB/133.2 MiB]  52% Done   3.0 MiB/s ETA 00:00:21           \r",
      "/\r",
      "-\r",
      "- [3/4 files][ 72.2 MiB/133.2 MiB]  54% Done   2.8 MiB/s ETA 00:00:22           \r",
      "\\\r",
      "|\r",
      "| [3/4 files][ 76.3 MiB/133.2 MiB]  57% Done   3.2 MiB/s ETA 00:00:18           \r",
      "/\r",
      "/ [3/4 files][ 79.9 MiB/133.2 MiB]  60% Done   3.3 MiB/s ETA 00:00:16           \r",
      "-\r",
      "\\\r",
      "\\ [3/4 files][ 84.3 MiB/133.2 MiB]  63% Done   3.3 MiB/s ETA 00:00:15           \r",
      "|\r",
      "| [3/4 files][ 87.1 MiB/133.2 MiB]  65% Done   3.3 MiB/s ETA 00:00:14           \r",
      "/\r",
      "-\r",
      "- [3/4 files][ 90.2 MiB/133.2 MiB]  67% Done   3.5 MiB/s ETA 00:00:12           \r",
      "\\\r",
      "|\r",
      "| [3/4 files][ 94.1 MiB/133.2 MiB]  70% Done   3.5 MiB/s ETA 00:00:11           \r",
      "/\r",
      "/ [3/4 files][ 98.2 MiB/133.2 MiB]  73% Done   3.6 MiB/s ETA 00:00:10           \r",
      "-\r",
      "\\\r",
      "\\ [3/4 files][102.6 MiB/133.2 MiB]  77% Done   3.6 MiB/s ETA 00:00:08           \r",
      "|\r",
      "| [3/4 files][104.9 MiB/133.2 MiB]  78% Done   3.5 MiB/s ETA 00:00:08           \r",
      "/\r",
      "-\r",
      "- [3/4 files][107.3 MiB/133.2 MiB]  80% Done   3.3 MiB/s ETA 00:00:08           \r",
      "\\\r",
      "|\r",
      "| [3/4 files][110.9 MiB/133.2 MiB]  83% Done   3.1 MiB/s ETA 00:00:07           \r",
      "/\r",
      "/ [3/4 files][115.0 MiB/133.2 MiB]  86% Done   3.1 MiB/s ETA 00:00:06           \r",
      "-\r",
      "\\\r",
      "\\ [3/4 files][118.9 MiB/133.2 MiB]  89% Done   3.1 MiB/s ETA 00:00:05           \r",
      "|\r",
      "/\r",
      "/ [3/4 files][123.0 MiB/133.2 MiB]  92% Done   3.5 MiB/s ETA 00:00:03           \r",
      "-\r",
      "- [3/4 files][126.3 MiB/133.2 MiB]  94% Done   3.6 MiB/s ETA 00:00:02           \r",
      "\\\r",
      "|\r",
      "| [3/4 files][130.2 MiB/133.2 MiB]  97% Done   3.6 MiB/s ETA 00:00:01           \r",
      "/\r",
      "-\r",
      "- [4/4 files][133.2 MiB/133.2 MiB] 100% Done   3.5 MiB/s ETA 00:00:00           \r\n",
      "Operation completed over 4 objects/133.2 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gsutil -m cp -r gs://${BUCKET}/data/* ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty BigQuery dataset and load sample JSON data\n",
    "Note: Ingesting the 400K rows of sample data. This usually takes 5-7 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# create BigQuery dataset if it doesn't already exist\n",
    "exists=$(bq ls -d | grep -w GA360_test)\n",
    "if [ -n \"$exists\" ]; then\n",
    "   echo \"Not creating GA360_test since it already exists.\"\n",
    "else\n",
    "   echo \"Creating GA360_test dataset.\"\n",
    "   bq --project_id=${PROJECT} mk GA360_test \n",
    "fi\n",
    "\n",
    "# create the schema and load our sample Google Analytics session data\n",
    "bq load --source_format=NEWLINE_DELIMITED_JSON \\\n",
    " GA360_test.ga_sessions_sample \\\n",
    " gs://${BUCKET}/data/ga_sessions_sample.json.gz \\\n",
    " data/ga_sessions_sample_schema.json # can't load schema files from GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install WALS model training package and model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a distributable package. Copy the package up to the code folder in the bucket you created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Creating distributable package ##############\n",
      "running sdist\n",
      "running egg_info\n",
      "writing wals_ml_engine.egg-info/PKG-INFO\n",
      "writing dependency_links to wals_ml_engine.egg-info/dependency_links.txt\n",
      "writing requirements to wals_ml_engine.egg-info/requires.txt\n",
      "writing top-level names to wals_ml_engine.egg-info/top_level.txt\n",
      "reading manifest file 'wals_ml_engine.egg-info/SOURCES.txt'\n",
      "writing manifest file 'wals_ml_engine.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating wals_ml_engine-0.1\n",
      "creating wals_ml_engine-0.1/trainer\n",
      "creating wals_ml_engine-0.1/wals_ml_engine.egg-info\n",
      "copying files to wals_ml_engine-0.1...\n",
      "copying README.txt -> wals_ml_engine-0.1\n",
      "copying setup.py -> wals_ml_engine-0.1\n",
      "copying trainer/__init__.py -> wals_ml_engine-0.1/trainer\n",
      "copying trainer/model.py -> wals_ml_engine-0.1/trainer\n",
      "copying trainer/task.py -> wals_ml_engine-0.1/trainer\n",
      "copying trainer/util.py -> wals_ml_engine-0.1/trainer\n",
      "copying trainer/wals.py -> wals_ml_engine-0.1/trainer\n",
      "copying wals_ml_engine.egg-info/PKG-INFO -> wals_ml_engine-0.1/wals_ml_engine.egg-info\n",
      "copying wals_ml_engine.egg-info/SOURCES.txt -> wals_ml_engine-0.1/wals_ml_engine.egg-info\n",
      "copying wals_ml_engine.egg-info/dependency_links.txt -> wals_ml_engine-0.1/wals_ml_engine.egg-info\n",
      "copying wals_ml_engine.egg-info/requires.txt -> wals_ml_engine-0.1/wals_ml_engine.egg-info\n",
      "copying wals_ml_engine.egg-info/top_level.txt -> wals_ml_engine-0.1/wals_ml_engine.egg-info\n",
      "Writing wals_ml_engine-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'wals_ml_engine-0.1' (and everything under it)\n",
      "############## Copying ML package to bucket ##############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://dist/wals_ml_engine-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [0 files][    0.0 B/  7.9 KiB]                                                \r",
      "/ [1 files][  7.9 KiB/  7.9 KiB]                                                \r\n",
      "Operation completed over 1 objects/7.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd wals_ml_engine\n",
    "\n",
    "echo \"############## Creating distributable package ##############\"\n",
    "python setup.py sdist\n",
    "\n",
    "echo \"############## Copying ML package to bucket ##############\"\n",
    "gsutil cp dist/wals_ml_engine-0.1.tar.gz gs://${BUCKET}/code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run the WALS model on the sample data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# view the ML train local script before running\n",
    "cat wals_ml_engine/mltrain.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 14 10:00:51 CDT 2019\n",
      "Sun Jul 14 10:00:55 CDT 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Train Start: 2019-07-14 10:00:53\n",
      "/Users/pankaj/PycharmProjects/ml-guild-capstone/endtoend/wals_ml_engine/trainer/wals.py:78: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  frac = np.array(1.0/(data > 0.0).sum(axis))\n",
      "WARNING:tensorflow:From /Users/pankaj/.virtualenvs/PycharmProjects/ml-guild-capstone/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-07-14 10:00:54.635943: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Train Finish: 2019-07-14 10:00:55\n",
      "INFO:tensorflow:train RMSE = 0.89\n",
      "INFO:tensorflow:test RMSE = 1.06\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd wals_ml_engine\n",
    "\n",
    "\n",
    "# train with user item ratings data\n",
    "./mltrain.sh local ../data/u.data\n",
    "# train locally with unoptimized hyperparams\n",
    "#./mltrain.sh local ../data/recommendation_events.csv --data-type web_views --use-optimized\n",
    "\n",
    "# train on ML Engine with optimized hyperparams\n",
    "# ./mltrain.sh train ../data/recommendation_events.csv --data-type web_views --use-optimized\n",
    "\n",
    "# tune hyperparams on ML Engine:\n",
    "# ./mltrain.sh tune ../data/recommendation_events.csv --data-type web_views\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a couple minutes, and create a job directory under wals_ml_engine/jobs like \"wals_ml_local_20180102_012345/model\", containing the model files saved as numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the locally trained model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mwals_ml_local_20190708_132650\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls wals_ml_engine/jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Copy the model files from this directory to the model folder in the project bucket:\n",
    "In the case of multiple models, take the most recent (tail -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation model file numpy arrays in bucket:\n",
      "gs://recserve_mlongcp/model/col.npy\n",
      "gs://recserve_mlongcp/model/item.npy\n",
      "gs://recserve_mlongcp/model/row.npy\n",
      "gs://recserve_mlongcp/model/user.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://wals_ml_engine/jobs/wals_ml_local_20190708_132650/model/col.npy [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 33.0 KiB]                                                \r",
      "/ [0 files][ 33.0 KiB/ 33.0 KiB]                                                \r",
      "-\r",
      "- [1 files][ 33.0 KiB/ 33.0 KiB]                                                \r",
      "Copying file://wals_ml_engine/jobs/wals_ml_local_20190708_132650/model/item.npy [Content-Type=application/octet-stream]...\n",
      "- [1 files][ 33.0 KiB/814.4 KiB]                                                \r",
      "- [1 files][296.4 KiB/814.4 KiB]                                                \r",
      "\\\r",
      "\\ [1 files][560.4 KiB/814.4 KiB]                                                \r",
      "|\r",
      "/\r",
      "/ [2 files][814.4 KiB/814.4 KiB]                                                \r",
      "-\r",
      "Copying file://wals_ml_engine/jobs/wals_ml_local_20190708_132650/model/row.npy [Content-Type=application/octet-stream]...\n",
      "- [2 files][814.4 KiB/832.9 KiB]  208.7 KiB/s                                   \r",
      "- [3 files][832.9 KiB/832.9 KiB]  200.5 KiB/s                                   \r",
      "Copying file://wals_ml_engine/jobs/wals_ml_local_20190708_132650/model/user.npy [Content-Type=application/octet-stream]...\n",
      "- [3 files][832.9 KiB/  1.6 MiB]  200.5 KiB/s                                   \r",
      "- [3 files][  1.1 MiB/  1.6 MiB]  204.3 KiB/s                                   \r",
      "\\\r",
      "\\ [3 files][  1.3 MiB/  1.6 MiB]  163.8 KiB/s                                   \r",
      "|\r",
      "| [3 files][  1.6 MiB/  1.6 MiB]  126.2 KiB/s                                   \r",
      "/\r",
      "/ [4 files][  1.6 MiB/  1.6 MiB]   84.7 KiB/s                                   \r",
      "-\r\n",
      "Operation completed over 4 objects/1.6 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export JOB_MODEL=$(find wals_ml_engine/jobs -name \"model\" | tail -1)\n",
    "gsutil cp ${JOB_MODEL}/* gs://${BUCKET}/model/\n",
    "  \n",
    "echo \"Recommendation model file numpy arrays in bucket:\"  \n",
    "gsutil ls gs://${BUCKET}/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://recserve_mlongcp/code/:\n",
      "gs://recserve_mlongcp/code/wals_ml_engine-0.1.tar.gz\n",
      "\n",
      "gs://recserve_mlongcp/data/:\n",
      "gs://recserve_mlongcp/data/ga_sessions_sample.json.gz\n",
      "gs://recserve_mlongcp/data/ga_sessions_sample_schema.json\n",
      "gs://recserve_mlongcp/data/recommendation_events.csv\n",
      "gs://recserve_mlongcp/data/u.data\n",
      "\n",
      "gs://recserve_mlongcp/model/:\n",
      "gs://recserve_mlongcp/model/col.npy\n",
      "gs://recserve_mlongcp/model/item.npy\n",
      "gs://recserve_mlongcp/model/row.npy\n",
      "gs://recserve_mlongcp/model/user.npy\n"
     ]
    }
   ],
   "source": [
    "# this how your bucket will look after uploading code, data and model\n",
    "\n",
    "!gsutil ls -R gs://${BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dockerize WebApp and launch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.772MB\r",
      "\r\n",
      "Step 1/9 : FROM python:3.7\n",
      " ---> 42d620af35be\n",
      "Step 2/9 : ENV APP /app\n",
      " ---> Using cache\n",
      " ---> 329dd7c28311\n",
      "Step 3/9 : RUN mkdir $APP\n",
      " ---> Using cache\n",
      " ---> c1be1f4a2720\n",
      "Step 4/9 : WORKDIR $APP\n",
      " ---> Using cache\n",
      " ---> 909f0e38041f\n",
      "Step 5/9 : EXPOSE 8000\n",
      " ---> Using cache\n",
      " ---> cdb40acb6232\n",
      "Step 6/9 : COPY requirements.txt .\n",
      " ---> Using cache\n",
      " ---> afe29c77db72\n",
      "Step 7/9 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 207c57ae6a51\n",
      "Step 8/9 : COPY . .\n",
      " ---> 57fe93ba5aa3\n",
      "Step 9/9 : CMD [\"gunicorn\", \"-b\", \"0.0.0.0:8000\", \"main:app\"]\n",
      " ---> Running in 946c77d1c7ae\n",
      "Removing intermediate container 946c77d1c7ae\n",
      " ---> 340e14aa7cea\n",
      "Successfully built 340e14aa7cea\n",
      "Successfully tagged luvneries/wals-api:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker build -t luvneries/wals-api app/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6c368596ba5c3329d78613ae6f575493e21211eeaa9f776e7499394f7cb2fbb0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run -d -p 8000:8000 luvneries/wals-api "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query API based on User ID and get recommended items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 {\"items\":[\"319\",\"1142\",\"1404\",\"1021\",\"1083\"]}\n",
      "196 {\"items\":[\"1149\",\"1462\",\"1191\",\"1183\",\"1188\"]}\n",
      "197 {\"items\":[\"168\",\"63\",\"317\",\"49\",\"97\"]}\n",
      "198 {\"items\":[\"898\",\"301\",\"913\",\"18\",\"271\"]}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for user_id in 195 196 197 198\n",
    "do \n",
    "    echo $user_id `curl -s http://127.0.0.1:8000/recommendation?userId=$user_id`\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
